name: local_llm # Logical name, referenced by Agent Profile's llm_config_ref
base_llm_config: base_default_llm # Inherits base configuration
type: llm_config
description_for_human: "LLM config for high-level strategic tasks (Principal/Partner)."

config:
  model: "openai/deepseek-chat"
  base_url:
    _type: "from_env"
    var: "GEMINI_BRIDGE_URL"
    default: "https://api.deepseek.com/v1"
    required: false
  api_key: "sk-0d9a4e9bd7a14a59b9eb49512235071a"
    # _type: "from_env"
    # var: "PRINCIPAL_LLM"
    # required: false
    # default: "gemini/gemini-2.5-pro-preview"
  temperature: 0.6
